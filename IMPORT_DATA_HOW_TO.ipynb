{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Скрипты для загрузки различных данных\n",
    "\n",
    "Ниже приведены скриты для загрузки данных различных модальностей:\n",
    " - ADNI\n",
    " - UCLA\n",
    " - UCLA APOE\n",
    " - Parkinson\n",
    " \n",
    "Каждый скрипт подгружает данные в виде матрицы размера n x k x k в переменную data и метки классов в переменную target размера 1 x n, где n - число объектов, k - количество вершин графа. В некоторых случаях\n",
    "так же подгружается переменная patients_ids хранящия метки пациентов (размера 1 x n). Для загрузки данных необходимо указать путь к папке в переменной path (или path_to_read). Функция convert используется для конвертации матриц размера n x n в вектора размера (n x n - n) / 2 (без диагонали) или (n x n - n) / 2 + n (с диагональю) хранящие верхний треуголник матрицы, и обратно из вектора в симметричную матрицу. \n",
    "\n",
    "Скрипты написаны для Python 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy.sparse import csr_matrix\n",
    "from convert import convert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADNI\n",
    "\n",
    "Данный набор данных содержит 807 снимков для 255 пациентов,\n",
    "каждому снимку поставлен в соответствие граф размера с 68 вершинами,\n",
    "метка класса (EMCI, Normal, AD, LMCI, SMC), а так же метка\n",
    "пациентов (так как для каждого пациента есть несколько снимков,\n",
    "метки класса для одного пациента одинаковы для всех его снимков)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADNI data shape                   : (807, 68, 68) \n",
      "ADNI target variable shape        : (807,) \n",
      "ADNI number of unique patients    : (255,)\n"
     ]
    }
   ],
   "source": [
    "path = 'connectomics/ADNI/Data/matrices/'\n",
    "\n",
    "all_matrices = pd.DataFrame(columns = ['subject_id_file','subject_id','scan_id', 'matrix', 'target'])\n",
    "\n",
    "# import data\n",
    "for foldername in sorted(os.listdir(path)):\n",
    "    for filename in sorted(os.listdir(path+foldername)):\n",
    "        if 'NORM' not in filename:\n",
    "            mat = np.genfromtxt(path+foldername+'/'+filename)\n",
    "            subject_id_file = foldername\n",
    "            subject_id = foldername[:-2]\n",
    "            scan_id = foldername[-1:]\n",
    "            \n",
    "            # ADNI data have zeros on 3 and 38 row and column\n",
    "            mat = np.delete(mat, [3,38], 1) \n",
    "            mat = np.delete(mat, [3,38], 0)\n",
    "                        \n",
    "            subject_data = convert(mat, mode = 'mat2vec')\n",
    "            single_subject = pd.DataFrame(data = [[subject_id_file, subject_id, scan_id, subject_data, np.nan]],\n",
    "                                          columns = ['subject_id_file','subject_id','scan_id', 'matrix', 'target'])\n",
    "            all_matrices = all_matrices.append(single_subject)\n",
    "            \n",
    "all_matrices.index = all_matrices.subject_id_file\n",
    "subject_data = pd.read_csv('connectomics/ADNI/Data/ADNI_subject_list.csv')\n",
    "subject_id_names = np.array(all_matrices['subject_id_file'])\n",
    "\n",
    "#importing target variables\n",
    "for name in subject_id_names:\n",
    "    smth = subject_data.loc[subject_data['Subject ID'] == name[:-2]]['DX Group'].dropna()\n",
    "    un_smth = np.unique(smth)\n",
    "    try:\n",
    "        val = un_smth[0].replace(' ', '')\n",
    "        all_matrices.set_value(name, 'target', val)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "#drop objects without any target\n",
    "all_matrices.dropna(inplace = True)\n",
    "data_copy = all_matrices.copy()\n",
    "\n",
    "\n",
    "\n",
    "temp = data_copy['matrix']\n",
    "\n",
    "data_vectors = np.zeros((807, 2346))\n",
    "data = np.zeros((807, 68, 68))\n",
    "\n",
    "for idx, vec in enumerate(temp):\n",
    "    data_vectors[idx] = vec\n",
    "    data[idx] = convert(vec)\n",
    "    \n",
    "target = all_matrices.target.values\n",
    "patients_ids = data_copy.subject_id.values\n",
    "\n",
    "print('ADNI data shape                   :', data.shape,\n",
    "     '\\nADNI target variable shape        :', target.shape,\n",
    "     '\\nADNI number of unique patients    :', data_copy.subject_id.unique().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCLA\n",
    "\n",
    "Набор данных UCLA содержит 94 снимка (людей с аутизмом и без), по 1 снимку для каждого пациента, каждому снимку поставлен в соответствие граф с 264 вершинами, переменная target содержит метки классов (1 - ASD - Аутизм, 0 - TD - норма)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCLA Autism data shape                   : (94, 264, 264) \n",
      "UCLA Autism target variable shape        : (94,)\n"
     ]
    }
   ],
   "source": [
    "path_to_read = 'connectomics/Autism/Data/dti/' #put your correct path here\n",
    "target_vector = [] #this will be a target vector (diagnosis)\n",
    "matrices=[] # this will be a list of connectomes \n",
    "\n",
    "for filename in sorted(os.listdir(path_to_read)): #for each file in a sorted (!) list of files:\n",
    "    if \"DTI_connectivity\" in filename: #we only need files with DTI connectivity matrices\n",
    "        if \"All\" not in filename: #we also do not need an average connectivity matrix here\n",
    "            A_dataframe = pd.read_csv(path_to_read + filename, sep = '   ', header = None, engine = 'python')\n",
    "            A = A_dataframe.values # we will use a list of numpy arrays, NOT pandas dataframes\n",
    "            matrices.append(A) #append a matrix to our list\n",
    "            if \"ASD\" in filename:\n",
    "                target_vector.append(1)\n",
    "            elif \"TD\" in filename: \n",
    "                target_vector.append(0)\n",
    "data = np.array(matrices)\n",
    "target = np.array(target_vector)\n",
    "\n",
    "print('UCLA Autism data shape                   :', data.shape,\n",
    "     '\\nUCLA Autism target variable shape        :', target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCLA APOE\n",
    "\n",
    "Набор данных UCLA APOE содержит 55 снимков (людей носителей алелли а4, наличие которой повышает вероятность возникновения болезни Паркинсона, и без нее) по 1 снимку для каждого человека, каждому снимку поставлен в соответствие граф со 110 вершинами, переменная target содержит метки классов (1 - носитель, 0 - нет)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCLA APOE data shape                   : (55, 110, 110) \n",
      "UCLA APOE target variable shape        : (55,)\n"
     ]
    }
   ],
   "source": [
    "path_to_read = \"UCLA_APOE_matrices/\" #put your correct path here\n",
    "target_vector_a4 = [] #this will be a target vector (diagnosis)\n",
    "matrices_a4=[] # this will be a list of connectomes \n",
    "\n",
    "for filename in sorted(os.listdir(path_to_read)): #for each file in a sorted (!) list of files:\n",
    "    if \"connectivity\" in filename: #we only need files with DTI connectivity matrices\n",
    "        if \"All\" not in filename: #we also do not need an average connectivity matrix here\n",
    "            A_dataframe = pd.read_csv(path_to_read + '/' + filename, sep = '   ', header = None, engine = 'python')\n",
    "            A = A_dataframe.values # we will use a list of numpy arrays, NOT pandas dataframes\n",
    "            matrices_a4.append(A) #append a matrix to our list\n",
    "            if \"APOE-4\" in filename:\n",
    "                target_vector_a4.append(1)\n",
    "            elif \"APOE-3\" in filename: \n",
    "                target_vector_a4.append(0)\n",
    "                \n",
    "data = np.array(matrices_a4)\n",
    "target = np.array(target_vector_a4)\n",
    "\n",
    "print('UCLA APOE data shape                   :', data.shape,\n",
    "     '\\nUCLA APOE target variable shape        :', target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARKINSON\n",
    "\n",
    "Данный набор данных содержит 553 снимка для 295 пациентов,\n",
    "каждому снимку поставлен в соответствие граф размера с 68 вершинами,\n",
    "метка класса (Prodromal, SWEDD, PD, Control, GenCohortUnaff, GenCohortPD), а так же метка\n",
    "пациентов (так как для каждого пациента есть несколько снимков,\n",
    "метки класса для одного пациента одинаковы для всех его снимков <-- не проверено)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parkinson  data shape                  : (553, 68, 68) \n",
      "Parkinson target variable shape        : (553,) \n",
      "Parkinson number of unique patients    : (295,)\n"
     ]
    }
   ],
   "source": [
    "path = 'connectomics/Parkinson/Data/'\n",
    "\n",
    "all_matrices = pd.DataFrame(columns = ['subject_id_file','subject_id',\n",
    "                                       #'subject_id','scan_id',\n",
    "                                       'matrix','centers', 'target'])\n",
    "data = []\n",
    "\n",
    "for foldername in sorted(os.listdir(path)):\n",
    "    for filename in sorted(os.listdir(path+foldername)):\n",
    "        if 'FULL' in filename:\n",
    "            mat = np.genfromtxt(path+foldername+'/'+filename)\n",
    "            subject_id_file = foldername\n",
    "            subject_id = subject_id_file[:8]\n",
    "            mat = mat[:70][:,:70]\n",
    "            mat = np.delete(mat, [3,38], 1)\n",
    "            mat = np.delete(mat, [3,38], 0)\n",
    "            data.append(mat)\n",
    "            subject_data = convert(mat,size = 68, mode = 'mat2vec')\n",
    "            \n",
    "        elif 'connect_grav' in filename:\n",
    "            centers = pd.read_csv(path+foldername+'/'+filename)\n",
    "            centers.drop([3,38], inplace=True)\n",
    "            subject_center = np.array(centers[['mm_cordX', 'mm_cordY', 'mm_cordZ']])\n",
    "                  \n",
    "            \n",
    "    single_subject = pd.DataFrame(data = [[subject_id_file, subject_id, subject_data, subject_center, np.nan]],\n",
    "                                  columns = ['subject_id_file','subject_id', 'matrix','centers', 'target'])\n",
    "    all_matrices = all_matrices.append(single_subject)\n",
    "all_matrices.index = all_matrices.subject_id_file\n",
    "\n",
    "\n",
    "meta_data = pd.read_csv('connectomics/Parkinson/demo_info.txt',header=None)\n",
    "meta_data.columns = ['subject_id_file', 'id', 'date','age','sex', 'target']\n",
    "meta_data.index = meta_data.subject_id_file\n",
    "\n",
    "all_matrices.target = meta_data.target\n",
    "\n",
    "data = np.array(data)\n",
    "target = all_matrices.target.values\n",
    "patients_ids = all_matrices.subject_id.values\n",
    "\n",
    "print('Parkinson  data shape                  :', data.shape,\n",
    "     '\\nParkinson target variable shape        :', target.shape,\n",
    "     '\\nParkinson number of unique patients    :', all_matrices.subject_id.unique().shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
